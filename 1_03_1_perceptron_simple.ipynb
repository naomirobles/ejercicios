{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrón simple\n",
    "(Ejercicio, 3 puntos posibles)\n",
    "\n",
    "En este notebook programaremos un perceptron simple utilizando numpy. El objetivo es que comprendamos el funcionamiento del perceptrón y que practiquemos la programación en Python. En la siguiente figura se encuentra una representación del perceptrón.\n",
    "\n",
    "<img src=\"files/simple_nn_notebook.png\">\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/irvingvasquez/cv2course_intro_nn/blob/master/02_red_neuronal_simple.ipynb)\n",
    "\n",
    "@juan1rving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos paquetes\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular producto punto\n",
    "\n",
    "El primer paso es calcular el valor intermedio, *h*, a partir del producto punto. La fórmula explícita es la siguiente:\n",
    "\n",
    "$$ h = W X +b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: (1 punto) Implementar la función h sin utilizar funciones predefinidas de numpy como numpy.dot()\n",
    "\n",
    "def combinacion_lineal(W, X, b):\n",
    "    suma = 0\n",
    "    for i in range(len(W)):\n",
    "        suma += W[i] * X[i]\n",
    "    suma = suma + b\n",
    "    \n",
    "    return suma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de activación\n",
    "\n",
    "Para este ejemplo utilizaremos la función escalón como función de activación.\n",
    "\n",
    "$$ \tf(h) = \\begin{cases}\n",
    "\t\t0 & \\text{if } h < a \\\\\n",
    "\t\t1 & \\text{if } h \\geq a\n",
    "\\end{cases}  $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: (1 punto) Completar el código\n",
    "def escalon(h):\n",
    "    return 1 if h >= 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir perceptrón\n",
    "\n",
    "Perceptrón como una función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptrón simple\n",
    "def perceptron(W, X, b, activacion):\n",
    "    h = combinacion_lineal(W, X, b)\n",
    "    return activacion(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar inferencia\n",
    "\n",
    "Ahora definamos unos pesos y veamos el resultado de una pasada frontal (fordward pass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Definamos unos pesos y sesgo\n",
    "inputs = np.array([0.7, -0.3])\n",
    "weights = np.array([0.1, 0.8])\n",
    "bias = -0.1\n",
    "\n",
    "# Pasada frontal\n",
    "activacion = escalon #definir la función a usar\n",
    "output = perceptron(weights, inputs, bias, activacion)\n",
    "\n",
    "print('Output:')\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Los pesos y bias que cumplen con la función OR son: \n",
      "Weights:  [0.55939477 0.79285701]\n",
      "Bias:  -0.5398398403448039\n",
      "Output del perceptrón:  [0. 1. 1. 1.]\n",
      "Número de intentos:  18\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO (1 punto): Realizar el pase frontal y encuentra por prueba y error los pesos que concuerdan con la función OR\n",
    "\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "outputs_OR = np.array([0, 1, 1, 1])\n",
    "\n",
    "\n",
    "def perceptron_OR(W, inputs, b, activacion, imprimir):\n",
    "    output_perceptron = np.zeros(len(inputs))\n",
    "    for i in range(len(inputs)):\n",
    "        h = combinacion_lineal(W, inputs[i], b)\n",
    "        output_perceptron[i] = activacion(h)\n",
    "\n",
    "        if imprimir:\n",
    "            print(f'Input: {inputs[i]}, h: {h}, Output: {output_perceptron[i]}')\n",
    "\n",
    "    return output_perceptron\n",
    "\n",
    "\n",
    "continuar = True\n",
    "intentos = 0\n",
    "\n",
    "while continuar:\n",
    "    # Para cada intento, se generan pesos y bias aleatorios\n",
    "    weights = np.random.uniform(low=-1.0, high=1.0, size=2)\n",
    "    bias = np.random.uniform(low=-1.0, high=1.0)\n",
    "    \n",
    "    output_perceptron = perceptron_OR(weights, inputs, bias, escalon,False)\n",
    "    \n",
    "    if np.array_equal(output_perceptron, outputs_OR):\n",
    "        continuar = False\n",
    "        print(\"========================================================\")\n",
    "        print(\"Los pesos y bias que cumplen con la función OR son: \")\n",
    "        print(\"Weights: \", weights)\n",
    "        print(\"Bias: \", bias)\n",
    "        print(\"Output del perceptrón: \", output_perceptron)\n",
    "        print(\"Número de intentos: \", intentos)\n",
    "        print(\"========================================================\")\n",
    "    else:\n",
    "        continuar = True\n",
    "        intentos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos finales: [0.55939477 0.79285701], Bias final: -0.5398398403448039\n",
      "----------------------------------------------------\n",
      "Input: [0 0], h: -0.5398398403448039, Output: 0.0\n",
      "Input: [0 1], h: 0.2530171708355371, Output: 1.0\n",
      "Input: [1 0], h: 0.01955492958498306, Output: 1.0\n",
      "Input: [1 1], h: 0.8124119407653241, Output: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Probamos que los pesos y bias encontrados son correctos para las entradas\n",
    "print(f\"Pesos finales: {weights}, Bias final: {bias}\")\n",
    "print(\"----------------------------------------------------\")\n",
    "output_perceptron = perceptron_OR(weights, inputs, bias, escalon,True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
